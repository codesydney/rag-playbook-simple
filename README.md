# RAG System using LlamaIndex and LanceDB
This notebook demonstrates how to build a Retrieval-Augmented Generation (RAG) system for question answering on the jp-handbook-full.pdf document using:

- LlamaIndex for document processing and querying
- LanceDB as the vector store

# Steps 

### 1. Install Required Dependencies
##### Notes:
    - Inside VS Code, I have to install the Jupyter Notebook extension, it installs a kernel and I have to choose Python environment instead of Jupyiter server.
    - Installation of required libraries. 

### 2. Import Libraries
##### Notes:

### 3. Load and Process the PDF Document
##### Notes:

### 4. Parse the Document into Nodes
##### Notes:

### 5. Set Up LanceDB Vector Store
##### Notes:

### 6. Create a Query Engine
##### Notes:

### 7. Ask Questions
##### Notes:

### 8. Multiple Q&A
##### Notes:

### 9. Interactive Q&A
##### Notes:

### 10. Conclusion
##### Notes:

## License

[MIT](https://choosealicense.com/licenses/mit/)
